{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61da45fb-44cc-47d9-88ed-2e900210b242",
   "metadata": {},
   "source": [
    "**The Graph Structure of Public Software Development**\n",
    "\n",
    "Antoine Pietri(1), Guillaume Rousseau(2) and Stefano Zacchiroli(3)\n",
    "\n",
    "1. Inria, Paris, France. antoine.pietri@inria.fr\n",
    "2. Universit\\'e de Paris, Paris, France. guillaume.rousseau@u-paris.fr\n",
    "3. LTCI, Tlcom Paris, Institut Polytechnique de Paris, Paris, France. stefano.zacchiroli@telecom-paris.fr\n",
    "\n",
    "**TODO: Add citation string**\n",
    "\n",
    "# Replication Package : Quality and Data Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f99159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tabulate\n",
    "from IPython.display import HTML, display\n",
    "import json\n",
    "\n",
    "import common\n",
    "\n",
    "\n",
    "DATASET = Path('../experiments')\n",
    "\n",
    "def d(p):\n",
    "    x, y = common.load_text_distribution(p)\n",
    "    return common.Distribution(x, y, '', '', '')\n",
    "\n",
    "distributions = {\n",
    "    'In-degrees': [\n",
    "        (\"Full\", d(DATASET / 'inout/full_in.txt')),\n",
    "        (\"Filesystem\", d(DATASET / 'inout/dir+cnt_in.txt')),\n",
    "        (\"Commit\", d(DATASET / 'inout/rev_in.txt')),\n",
    "        (\"History\", d(DATASET / 'inout/rel+rev_in.txt')),\n",
    "        (\"Hosting\", d(DATASET / 'inout/ori+snp_in.txt')),\n",
    "    ],\n",
    "    'Out-degrees': [\n",
    "        (\"Full\", d(DATASET / 'inout/full_out.txt')),\n",
    "        (\"Filesystem\", d(DATASET / 'inout/dir+cnt_out.txt')),\n",
    "        (\"Commit\", d(DATASET / 'inout/rev_out.txt')),\n",
    "        (\"History\", d(DATASET / 'inout/rel+rev_out.txt')),\n",
    "        (\"Hosting\", d(DATASET / 'inout/ori+snp_out.txt')),\n",
    "    ],\n",
    "    'Connected components': [\n",
    "        (\"Full\", d(DATASET / 'connectedcomponents/full/distribution.txt')),\n",
    "        (\"Filesystem\", d(DATASET / 'connectedcomponents/dir+cnt/distribution.txt')),\n",
    "        (\"Commit\", d(DATASET / 'connectedcomponents/rev/distribution.txt')),\n",
    "        (\"History\", d(DATASET / 'connectedcomponents/rel+rev/distribution.txt')),\n",
    "        (\"Hosting\", d(DATASET / 'connectedcomponents/ori+snp/distribution.txt')),\n",
    "    ],\n",
    "    'Clustering coefficient': [\n",
    "        (\"Full\", d(DATASET / 'clusteringcoeff/distribution-full.txt')),\n",
    "        (\"Filesystem\", d(DATASET / 'clusteringcoeff/distribution-dircnt.txt')),\n",
    "        (\"Commit\", d(DATASET / 'clusteringcoeff/distribution-rev.txt')),\n",
    "        (\"History\", d(DATASET / 'clusteringcoeff/distribution-relrev.txt')),\n",
    "        # (\"Hosting\", d(DATASET / 'clusteringcoeff/distribution-orisnp.txt')),\n",
    "    ],\n",
    "    'Shortest path': [\n",
    "        (\"Filesystem\", d(DATASET / 'shortestpath/dir+cnt/distribution.txt')),\n",
    "        (\"Commit\", d(DATASET / 'shortestpath/rev/distribution.txt')),\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef5d673",
   "metadata": {},
   "source": [
    "## Graph layer statistics\n",
    "\n",
    "Statistics of the graph layers and their associated distributions, as reported in the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6592ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Algorithm             </th><th>Layer     </th><th>Number of objects  </th><th style=\"text-align: right;\">  Scaling parameter</th><th style=\"text-align: right;\">  X decades</th><th style=\"text-align: right;\">  Y decades</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>In-degrees            </td><td>Full      </td><td>19,330,739,526     </td><td style=\"text-align: right;\">            1.86533</td><td style=\"text-align: right;\">    8.47619</td><td style=\"text-align: right;\">   10.1453 </td></tr>\n",
       "<tr><td>In-degrees            </td><td>Filesystem</td><td>17,050,437,427     </td><td style=\"text-align: right;\">            1.86295</td><td style=\"text-align: right;\">    8.47619</td><td style=\"text-align: right;\">   10.0273 </td></tr>\n",
       "<tr><td>In-degrees            </td><td>Commit    </td><td>1,976,476,233      </td><td style=\"text-align: right;\">            2.20457</td><td style=\"text-align: right;\">    5.84003</td><td style=\"text-align: right;\">    9.23299</td></tr>\n",
       "<tr><td>In-degrees            </td><td>History   </td><td>1,993,015,770      </td><td style=\"text-align: right;\">            2.14762</td><td style=\"text-align: right;\">    5.84003</td><td style=\"text-align: right;\">    9.23155</td></tr>\n",
       "<tr><td>In-degrees            </td><td>Hosting   </td><td>287,286,329        </td><td style=\"text-align: right;\">            2.76256</td><td style=\"text-align: right;\">    7.03349</td><td style=\"text-align: right;\">    8.16881</td></tr>\n",
       "<tr><td>Out-degrees           </td><td>Full      </td><td>19,330,739,526     </td><td style=\"text-align: right;\">            1.94752</td><td style=\"text-align: right;\">    6.01419</td><td style=\"text-align: right;\">    9.96291</td></tr>\n",
       "<tr><td>Out-degrees           </td><td>Filesystem</td><td>17,050,437,427     </td><td style=\"text-align: right;\">            1.94683</td><td style=\"text-align: right;\">    6.01419</td><td style=\"text-align: right;\">    9.96169</td></tr>\n",
       "<tr><td>Out-degrees           </td><td>Commit    </td><td>1,976,476,233      </td><td style=\"text-align: right;\">            5.80822</td><td style=\"text-align: right;\">    5      </td><td style=\"text-align: right;\">    9.24394</td></tr>\n",
       "<tr><td>Out-degrees           </td><td>History   </td><td>1,993,015,770      </td><td style=\"text-align: right;\">            5.80822</td><td style=\"text-align: right;\">    5      </td><td style=\"text-align: right;\">    9.24802</td></tr>\n",
       "<tr><td>Out-degrees           </td><td>Hosting   </td><td>287,286,329        </td><td style=\"text-align: right;\">            2.20614</td><td style=\"text-align: right;\">    4.98671</td><td style=\"text-align: right;\">    8.22387</td></tr>\n",
       "<tr><td>Connected components  </td><td>Full      </td><td>33,104,255         </td><td style=\"text-align: right;\">            2.37898</td><td style=\"text-align: right;\">   10.2765 </td><td style=\"text-align: right;\">    7.35623</td></tr>\n",
       "<tr><td>Connected components  </td><td>Filesystem</td><td>46,286,502         </td><td style=\"text-align: right;\">            2.25331</td><td style=\"text-align: right;\">   10.2192 </td><td style=\"text-align: right;\">    7.54798</td></tr>\n",
       "<tr><td>Connected components  </td><td>Commit    </td><td>88,031,649         </td><td style=\"text-align: right;\">            2.10415</td><td style=\"text-align: right;\">    7.71218</td><td style=\"text-align: right;\">    7.5815 </td></tr>\n",
       "<tr><td>Connected components  </td><td>History   </td><td>88,040,059         </td><td style=\"text-align: right;\">            2.1037 </td><td style=\"text-align: right;\">    7.71747</td><td style=\"text-align: right;\">    7.5762 </td></tr>\n",
       "<tr><td>Connected components  </td><td>Hosting   </td><td>108,342,722        </td><td style=\"text-align: right;\">            2.97852</td><td style=\"text-align: right;\">    7.14119</td><td style=\"text-align: right;\">    7.6733 </td></tr>\n",
       "<tr><td>Clustering coefficient</td><td>Full      </td><td>13,792,507         </td><td style=\"text-align: right;\">            2.06372</td><td style=\"text-align: right;\">    5.25442</td><td style=\"text-align: right;\">    7.11542</td></tr>\n",
       "<tr><td>Clustering coefficient</td><td>Filesystem</td><td>13,792,508         </td><td style=\"text-align: right;\">            2.10927</td><td style=\"text-align: right;\">    5.25442</td><td style=\"text-align: right;\">    7.1271 </td></tr>\n",
       "<tr><td>Clustering coefficient</td><td>Commit    </td><td>13,792,508         </td><td style=\"text-align: right;\">            2.52565</td><td style=\"text-align: right;\">    1.95424</td><td style=\"text-align: right;\">    7.13776</td></tr>\n",
       "<tr><td>Clustering coefficient</td><td>History   </td><td>13,792,508         </td><td style=\"text-align: right;\">            2.52565</td><td style=\"text-align: right;\">    1.95424</td><td style=\"text-align: right;\">    7.13776</td></tr>\n",
       "<tr><td>Shortest path         </td><td>Filesystem</td><td>586,361,673,140    </td><td style=\"text-align: right;\">            2.2753 </td><td style=\"text-align: right;\">    2.71096</td><td style=\"text-align: right;\">   11.2086 </td></tr>\n",
       "<tr><td>Shortest path         </td><td>Commit    </td><td>172,688,913        </td><td style=\"text-align: right;\">            1.53686</td><td style=\"text-align: right;\">    6.62941</td><td style=\"text-align: right;\">    7.5815 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# it can take few minutes to process\n",
    "headers = [\"Algorithm\", \"Layer\", \"Number of objects\", \"Scaling parameter\", \"X decades\", \"Y decades\"]\n",
    "table = []\n",
    "for algo_name, algo_distributions in distributions.items():\n",
    "    for name, distribution in algo_distributions:\n",
    "        row = [\n",
    "            algo_name,\n",
    "            name,\n",
    "            f'{int(np.sum(distribution.y)):,}',\n",
    "            distribution.fitted_power(),\n",
    "            np.log10(np.max(distribution.x)),\n",
    "            np.log10(np.max(distribution.y)),\n",
    "        ]\n",
    "        table.append(row)\n",
    "\n",
    "display(HTML(tabulate.tabulate(table, headers=headers, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06106573-b5ee-4ecd-b9a4-4046eb5c1d50",
   "metadata": {},
   "source": [
    "## Data integrity: in and out degrees\n",
    "\n",
    "This data helps getting an overview of the graph properties and check whether it is consistent to our expectations as a way to perform data integrity checks.\n",
    "\n",
    "### Node and edge statistics of the studied graph corpus.\n",
    "\n",
    "It corresponds to https://annex.softwareheritage.org/public/dataset/graph/2020-12-15/compressed/ (same as Table 1)\n",
    "\n",
    "**TODO** Confirm that these numbers do not come from a calculation based on the distributions but from the raw data, and provide script to generate them from raw data.\n",
    "https://forge.softwareheritage.org/source/swh-dataset/browse/master/swh/dataset/exporters/edges.py$150-230\n",
    "? Add extra link \n",
    "\n",
    "|Layer|Node type|Nodes|%|\n",
    "|:------|:------|------:|---:|\n",
    "|hosting|origins|147 453 557|0.76%|\n",
    "||snapshots|139 832 772|0.72%|\n",
    "|history|releases|16 539 537|0.09%|\n",
    "||commits|1 976 476 233|10.22%|\n",
    "|filesystem|directories|7 897 590 134|40.86%|\n",
    "||contents|9 152 847 293|47.35%|\n",
    "||Total|19 330 739 526|100%|\n",
    "\n",
    "|Layer|Edge type|Edges|%|\n",
    "|:------|:------|------:|---:|\n",
    "|hosting|origin $\\to$ snapshot|776 112 709|0.35%|\n",
    "||snapshot   $\\to$ commit|1 358 538 567|0.61%|\n",
    "||snapshot   $\\to$ release|70 0823 546|0.32%|\n",
    "|history|release    $\\to$ commit|16 492 908|0.01%|\n",
    "||commit     $\\to$ commit|2 021 009 703|0.91%|\n",
    "||commit     $\\to$ directory|1 971 187 167|0.89%|\n",
    "|filesystem|directory  $\\to$ directory|64 584 351 336|29.16%|\n",
    "||directory  $\\to$ commit|792 196 260|0.36%|\n",
    "||directory  $\\to$ content|149 267 317 723|67.39%|\n",
    "||Total|221 488 073 659|100%|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "04d4d966-3764-44b0-b756-53bdbabec1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw stats from the compress dataset 2021-12-15\n",
    "# (before any statistical processing)\n",
    "short2longname={\"ori\":\"origin\",\"snp\":\"snapshot\",\"rel\":\"release\",\n",
    "                \"rev\":\"commit\",\"dir\":\"directory\",\"cnt\":\"content\"}\n",
    "rawstats={\"nodes\":\n",
    "          {\n",
    "              \"origin\":147453557,\n",
    "              \"snapshot\":139832772,\n",
    "              \"release\":16539537,\n",
    "              \"commit\":1976476233,\n",
    "              \"directory\":7897590134,\n",
    "              \"content\":9152847293\n",
    "          },\n",
    "          \"edges\":{\n",
    "              \"origin\":{\"snapshot\":776112709},\n",
    "              \"snapshot\":{\"commit\":1358538567,\"release\":700823546},\n",
    "              \"release\":{\"commit\":16492908},\n",
    "              \"commit\":{\"commit\":2021009703,\"directory\":1971187167},\n",
    "              \"directory\":{\"directory\":64584351336,\"commit\":792196260,\"content\":149267317723}\n",
    "          }\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4df511-1f71-4c03-8546-f6954d494c1f",
   "metadata": {},
   "source": [
    "### Criteria list\n",
    "Here are a few examples of criteria that can be checked on the table:\n",
    "\n",
    "1. The number of nodes computed from the distributions (= the sum of the second column) is always the same in all distributions starting from the same node type. For instance, `dir_in_*` and `dir_out_*` all have the same number of directory nodes which have to be equals to the number of directory nodes in the raw swh dataset (namely 7 897 590 134).\n",
    "1. The number of edges computed from a source type to a destination type (src_out_dest) equals the number of edges from the raw dataset.\n",
    "1. The total (or average) in/outdegree of a given object type is consistent when each neighbor type is looked independently and when they are all aggregated together (e.g. the average degree of `dir_out_all` is a weighted average of the average degrees of the `dir_out_{cnt,dir,rev}` distributions).\n",
    "1. The number of objects with a total indegree of 0 should be small in all types of objects that are supposed to be reachable from the upper layers of the graph.\n",
    "1. The number of objects with a total outdegree of 0 should be small in specific types of objects that are supposed to reach the lower layers of the graph.\n",
    "1. Some specific per-layer indegrees are expected to be relatively small compared to the total number of objects (e.g. most revisions do not have an associated release)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ec9822e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Node type  </th><th>Direction  </th><th>Neighbor type  </th><th># Nodes      </th><th># Edges        </th><th style=\"text-align: right;\">  Avg degree</th><th># (Lowest degree)  </th><th># (Second-lowest)  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contents   </td><td>← in       </td><td>directories    </td><td>9,152,847,293</td><td>143,786,784,566</td><td style=\"text-align: right;\">  15.7095   </td><td>5,978,249,005 (1)  </td><td>1,098,223,970 (2)  </td></tr>\n",
       "<tr><td>directories</td><td>← in       </td><td>everything     </td><td>7,897,590,134</td><td>65,200,402,547 </td><td style=\"text-align: right;\">   8.25573  </td><td>1,343,830 (0)      </td><td>6,134,767,929 (1)  </td></tr>\n",
       "<tr><td>directories</td><td>← in       </td><td>directories    </td><td>7,897,590,134</td><td>63,229,213,027 </td><td style=\"text-align: right;\">   8.00614  </td><td>1,607,262,793 (0)  </td><td>4,669,554,466 (1)  </td></tr>\n",
       "<tr><td>directories</td><td>← in       </td><td>revisions      </td><td>7,897,590,134</td><td>1,971,187,167  </td><td style=\"text-align: right;\">   0.249594 </td><td>6,261,880,169 (0)  </td><td>1,504,272,429 (1)  </td></tr>\n",
       "<tr><td>directories</td><td>→ out      </td><td>everything     </td><td>7,897,590,134</td><td>207,805,470,722</td><td style=\"text-align: right;\">  26.3125   </td><td>557,087 (0)        </td><td>1,713,055,834 (1)  </td></tr>\n",
       "<tr><td>directories</td><td>→ out      </td><td>contents       </td><td>7,897,590,134</td><td>143,786,781,408</td><td style=\"text-align: right;\">  18.2064   </td><td>1,787,869,540 (0)  </td><td>1,421,143,792 (1)  </td></tr>\n",
       "<tr><td>directories</td><td>→ out      </td><td>directories    </td><td>7,897,590,134</td><td>63,229,213,027 </td><td style=\"text-align: right;\">   8.00614  </td><td>2,753,589,255 (0)  </td><td>1,734,567,306 (1)  </td></tr>\n",
       "<tr><td>directories</td><td>→ out      </td><td>revisions      </td><td>7,897,590,134</td><td>789,473,873    </td><td style=\"text-align: right;\">   0.0999639</td><td>7,860,017,187 (0)  </td><td>23,267,141 (1)     </td></tr>\n",
       "<tr><td>origins    </td><td>→ out      </td><td>snapshots      </td><td>147,453,557  </td><td>189,314,705    </td><td style=\"text-align: right;\">   1.28389  </td><td>22,710,546 (0)     </td><td>77,244,971 (1)     </td></tr>\n",
       "<tr><td>releases   </td><td>← in       </td><td>snapshots      </td><td>16,539,537   </td><td>700,135,072    </td><td style=\"text-align: right;\">  42.331    </td><td>427,531 (0)        </td><td>4,408,973 (1)      </td></tr>\n",
       "<tr><td>revisions  </td><td>← in       </td><td>everything     </td><td>1,976,476,233</td><td>3,972,106,851  </td><td style=\"text-align: right;\">   2.00969  </td><td>21,591,750 (0)     </td><td>1,725,674,679 (1)  </td></tr>\n",
       "<tr><td>revisions  </td><td>← in       </td><td>directories    </td><td>1,976,476,233</td><td>789,473,873    </td><td style=\"text-align: right;\">   0.399435 </td><td>1,964,431,618 (0)  </td><td>5,859,359 (1)      </td></tr>\n",
       "<tr><td>revisions  </td><td>← in       </td><td>releases       </td><td>1,976,476,233</td><td>16,492,908     </td><td style=\"text-align: right;\">   0.0083446</td><td>1,964,753,264 (0)  </td><td>11,174,521 (1)     </td></tr>\n",
       "<tr><td>revisions  </td><td>← in       </td><td>revisions      </td><td>1,976,476,233</td><td>2,019,963,947  </td><td style=\"text-align: right;\">   1.022    </td><td>144,984,204 (0)    </td><td>1,709,984,716 (1)  </td></tr>\n",
       "<tr><td>revisions  </td><td>← in       </td><td>snapshots      </td><td>1,976,476,233</td><td>1,146,176,123  </td><td style=\"text-align: right;\">   0.579909 </td><td>1,797,791,879 (0)  </td><td>97,843,227 (1)     </td></tr>\n",
       "<tr><td>revisions  </td><td>→ out      </td><td>revisions      </td><td>1,976,476,233</td><td>2,019,963,947  </td><td style=\"text-align: right;\">   1.022    </td><td>90,031,800 (0)     </td><td>1,753,640,553 (1)  </td></tr>\n",
       "<tr><td>snapshots  </td><td>← in       </td><td>origins        </td><td>139,832,772  </td><td>189,320,602    </td><td style=\"text-align: right;\">   1.35391  </td><td>53,736 (0)         </td><td>129,905,452 (1)    </td></tr>\n",
       "<tr><td>snapshots  </td><td>→ out      </td><td>everything     </td><td>139,832,772  </td><td>1,846,275,796  </td><td style=\"text-align: right;\">  13.2035   </td><td>43,567 (0)         </td><td>90,198,552 (1)     </td></tr>\n",
       "<tr><td>snapshots  </td><td>→ out      </td><td>releases       </td><td>139,832,772  </td><td>700,096,853    </td><td style=\"text-align: right;\">   5.00667  </td><td>127,431,334 (0)    </td><td>2,406,919 (1)      </td></tr>\n",
       "<tr><td>snapshots  </td><td>→ out      </td><td>revisions      </td><td>139,832,772  </td><td>1,146,176,123  </td><td style=\"text-align: right;\">   8.19676  </td><td>44,064 (0)         </td><td>92,104,696 (1)     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inout_per_type = [\n",
    "    'cnt_in_dir',\n",
    "    'dir_in_all',\n",
    "    'dir_in_dir',\n",
    "    'dir_in_rev',\n",
    "    'dir_out_all',\n",
    "    'dir_out_cnt',\n",
    "    'dir_out_dir',\n",
    "    'dir_out_rev',\n",
    "    'ori_out_snp',\n",
    "    'rel_in_snp',\n",
    "    'rev_in_all',\n",
    "    'rev_in_dir',\n",
    "    'rev_in_rel',\n",
    "    'rev_in_rev',\n",
    "    'rev_in_snp',\n",
    "    'rev_out_rev',\n",
    "    'snp_in_ori',\n",
    "    'snp_out_all',\n",
    "    'snp_out_rel',\n",
    "    'snp_out_rev',\n",
    "]\n",
    "\n",
    "headers = [\"Node type\", \"Direction\", \"Neighbor type\", \"# Nodes\", \"# Edges\", \"Avg degree\", \"# (Lowest degree)\", \"# (Second-lowest)\"]\n",
    "table2 = []\n",
    "for name in inout_per_type:\n",
    "    dist = d(DATASET / f'inout/per_type/{name}.txt')\n",
    "    src, direction, dst = name.split('_')\n",
    "    row = [\n",
    "        common.types_verbose[src],\n",
    "        (\"← in \" if direction == 'in' else \"→ out \"),\n",
    "        common.types_verbose[dst],\n",
    "        f'{int(np.sum(dist.y)):,}',\n",
    "        f'{int(np.sum(dist.x * dist.y)):,}',\n",
    "        np.sum(dist.x * dist.y) / np.sum(dist.y),\n",
    "        f'{int(dist.y[0]):,} ({int(dist.x[0]):,})',\n",
    "        f'{int(dist.y[1]):,} ({int(dist.x[1]):,})',\n",
    "    ]\n",
    "    table2.append(row)\n",
    "\n",
    "display(HTML(tabulate.tabulate(table2, headers=headers, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7701a6d-922b-4552-a16d-80460ceab696",
   "metadata": {},
   "source": [
    "### Control scripts "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc7e520-e53f-471d-ad8e-e2d19fe8f5b8",
   "metadata": {},
   "source": [
    "- control script according to criterion 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "37f427dd-9127-41aa-8f68-8890204a2fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control script according to criterion 1\n",
      "\n",
      "cnt in dir OK, dir in all OK, dir in dir OK, dir in rev OK, dir out all OK, dir out cnt OK, dir out dir OK, dir out rev OK, ori out snp OK, rel in snp OK, rev in all OK, rev in dir OK, rev in rel OK, rev in rev OK, rev in snp OK, rev out rev OK, snp in ori OK, snp out all OK, snp out rel OK, snp out rev OK, end\n",
      "\n",
      "Control status : Successful\n"
     ]
    }
   ],
   "source": [
    "print(\"Control script according to criterion 1\")\n",
    "print()\n",
    "DATASET = Path('../experiments')\n",
    "error=False\n",
    "for name in inout_per_type:\n",
    "    dist = d(DATASET / f'inout/per_type/{name}.txt')\n",
    "    src, direction, dst = name.split('_')\n",
    "    sy=np.sum(dist.y)\n",
    "    sxy=np.sum(dist.x*dist.y)\n",
    "    if dist.x[0]==0:\n",
    "        s0=dist.y[0]\n",
    "    else:\n",
    "        s0=0\n",
    "    if sy==rawstats[\"nodes\"][short2longname[src]]:\n",
    "        print(f'{src} {direction} {dst} OK,', end=\" \")\n",
    "    else:\n",
    "        print()\n",
    "        print(f'{src} {direction} {dst} ERROR {int(sy):,} {int(sxy):,}')\n",
    "        error=True\n",
    "print(\"end\")\n",
    "print()\n",
    "if error:\n",
    "    print(\"Control status : Failed\")\n",
    "else:\n",
    "    print(\"Control status : Successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d53087-60ee-476d-a24c-74f0f64d48af",
   "metadata": {},
   "source": [
    "- control script according to criterion 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6719acd4-cad8-4c65-b15b-88f6eb3fcfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control script according to criterion 2\n",
      "\n",
      "cnt in  dir ERROR   143,786,784,566 (derived)   149,267,317,723(raw) 0.036716229919602335\n",
      "dir in  dir ERROR    63,229,213,027 (derived)    64,584,351,336(raw) 0.020982455981479086\n",
      "dir in rev OK\n",
      "dir out cnt ERROR   143,786,781,408 (derived)   149,267,317,723(raw) 0.03671625107627647\n",
      "dir out dir ERROR    63,229,213,027 (derived)    64,584,351,336(raw) 0.020982455981479086\n",
      "dir out rev ERROR       789,473,873 (derived)       792,196,260(raw) 0.0034365057466946387\n",
      "ori out snp ERROR       189,314,705 (derived)       776,112,709(raw) 0.7560731800875586\n",
      "rel in  snp ERROR       700,135,072 (derived)       700,823,546(raw) 0.000982378522995573\n",
      "rev in  dir ERROR       789,473,873 (derived)       792,196,260(raw) 0.0034365057466946387\n",
      "rev in rel OK\n",
      "rev in  rev ERROR     2,019,963,947 (derived)     2,021,009,703(raw) 0.0005174423450059012\n",
      "rev in  snp ERROR     1,146,176,123 (derived)     1,358,538,567(raw) 0.15631683130568055\n",
      "rev out rev ERROR     2,019,963,947 (derived)     2,021,009,703(raw) 0.0005174423450059012\n",
      "snp in  ori ERROR       189,320,602 (derived)       776,112,709(raw) 0.7560655819643329\n",
      "snp out rel ERROR       700,096,853 (derived)       700,823,546(raw) 0.0010369129350000464\n",
      "snp out rev ERROR     1,146,176,123 (derived)     1,358,538,567(raw) 0.15631683130568055\n",
      "Control status : Failed\n"
     ]
    }
   ],
   "source": [
    "print(\"Control script according to criterion 2\")\n",
    "print()\n",
    "DATASET = Path('../experiments')\n",
    "\n",
    "error=False\n",
    "\n",
    "for name in inout_per_type:\n",
    "    dist = d(DATASET / f'inout/per_type/{name}.txt')\n",
    "    src, direction, dst = name.split('_')\n",
    "    sy=np.sum(dist.y)\n",
    "    sxy=np.sum(dist.x*dist.y)\n",
    "    if dist.x[0]==0:\n",
    "        s0=dist.y[0]\n",
    "    else:\n",
    "        s0=0\n",
    "    if direction==\"out\" and dst!=\"all\":\n",
    "        rs=rawstats[\"edges\"][short2longname[src]][short2longname[dst]]\n",
    "        if sxy==rs:\n",
    "            print(f'{src} {direction} {dst} OK')\n",
    "        else:\n",
    "            ds=(rs-sxy)/rs\n",
    "            print(f'{src} {direction} {dst} ERROR {int(sxy):17,} (derived) {rs:17,}(raw) {ds:<}')\n",
    "            error=True\n",
    "    if direction==\"in\" and dst!=\"all\":\n",
    "        rs=rawstats[\"edges\"][short2longname[dst]][short2longname[src]]\n",
    "        if sxy==rs:\n",
    "            print(f'{src} {direction} {dst} OK')\n",
    "        else:\n",
    "            ds=(rs-sxy)/rs\n",
    "            print(f'{src:3} {direction:3} {dst:3} ERROR {int(sxy):17,} (derived) {rs:17,}(raw) {ds:<}')\n",
    "            error=True\n",
    "\n",
    "if error:\n",
    "    print(\"Control status : Failed\")\n",
    "else:\n",
    "    print(\"Control status : Successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dd58a3-d46b-4df4-a2e0-63a14086e321",
   "metadata": {},
   "source": [
    "**Subject to further investigation, we observe here the deduplication due to compression, which means that the statistics measured are not those of the original graph (see section dedicated to internal threat to validity).** TODO(TBC).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020ce54b-fc57-48de-b39b-51da83a0ad8c",
   "metadata": {},
   "source": [
    "- control script according to criterion 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ccda6695-82fd-488c-a3a1-022e69f68412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control script according to criterion 3\n",
      "\n",
      "dir OK\n",
      "snp OK\n",
      "Control status : Successful\n"
     ]
    }
   ],
   "source": [
    "print(\"Control script according to criterion 3\")\n",
    "print()\n",
    "DATASET = Path('../experiments')\n",
    "\n",
    "error=False\n",
    "statsC3={}\n",
    "for name in inout_per_type:\n",
    "    dist = d(DATASET / f'inout/per_type/{name}.txt')\n",
    "    src, direction, dst = name.split('_')\n",
    "    sy=np.sum(dist.y)\n",
    "    sxy=np.sum(dist.x*dist.y)\n",
    "    if dist.x[0]==0:\n",
    "        s0=dist.y[0]\n",
    "    else:\n",
    "        s0=0\n",
    "    if direction==\"out\":\n",
    "        if dst!=\"all\":\n",
    "            try:\n",
    "                statsC3[src][\"*\"]+=sxy\n",
    "            except:\n",
    "                try:\n",
    "                    statsC3[src][\"*\"]=sxy\n",
    "                except:\n",
    "                    statsC3[src]={\"*\":sxy}\n",
    "        else:\n",
    "            try:\n",
    "                statsC3[src][\"all\"]=sxy\n",
    "            except:\n",
    "                statsC3[src]={\"all\":sxy}\n",
    "\n",
    "for src in statsC3:\n",
    "    if \"all\" in statsC3[src]:\n",
    "        if statsC3[src][\"all\"]!=statsC3[src][\"*\"]:\n",
    "                print(f'{src} OK')\n",
    "        else:\n",
    "                print(f'{src}  ERROR {statsC3[src][\"all\"]:,} {statsC3[src][\"*\"]:,}')\n",
    "                error=True\n",
    "\n",
    "if error:\n",
    "    print(\"Control status : Failed\")\n",
    "else:\n",
    "    print(\"Control status : Successful\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdedc110-82c8-4e2f-83a9-5017178d6eaf",
   "metadata": {},
   "source": [
    "- control script according to criterion 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2b382cbc-decf-4f21-9e92-dcd91aa49442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control script according to criterion 4\n",
      "\n",
      "dir in  all ERROR         1,343,830 0.00017015696904992107\n",
      "rel in  snp ERROR           427,531 0.025849030719541907\n",
      "rev in  all ERROR        21,591,750 0.010924366121634006\n",
      "snp in  ori ERROR            53,736 0.0003842875974739312\n",
      "end\n",
      "\n",
      "Control status : Failed\n"
     ]
    }
   ],
   "source": [
    "print(\"Control script according to criterion 4\")\n",
    "print()\n",
    "DATASET = Path('../experiments')\n",
    "\n",
    "error=False\n",
    "for name in inout_per_type:\n",
    "    dist = d(DATASET / f'inout/per_type/{name}.txt')\n",
    "    src, direction, dst = name.split('_')\n",
    "    sy=np.sum(dist.y)\n",
    "    sxy=np.sum(dist.x*dist.y)\n",
    "    if dist.x[0]==0:\n",
    "        s0=dist.y[0]\n",
    "    else:\n",
    "        s0=0\n",
    "    if ((dst==\"all\" and direction!=\"out\") or (direction==\"in\" and src!=\"dir\" and src!=\"rev\")) and s0!=0:\n",
    "    #if (dst==\"all\" or (direction==\"in\")) and s0!=0:\n",
    "        rs=rawstats[\"nodes\"][short2longname[src]]\n",
    "        ds=s0/rs\n",
    "        print(f'{src:3} {direction:3} {dst:3} ERROR {int(s0):17,} {ds:<}')\n",
    "        error=True\n",
    "print(\"end\")\n",
    "print()\n",
    "if error:\n",
    "    print(\"Control status : Failed\")\n",
    "else:\n",
    "    print(\"Control status : Successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13993b7c-c93f-4c03-a13f-6b278b3af5bb",
   "metadata": {},
   "source": [
    "- control script according to criterion 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2be240bd-52cb-47ae-a168-b233743457c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control script according to criterion 5\n",
      "\n",
      "dir out all ERROR           557,087 7.053885939226939e-05\n",
      "snp out all ERROR            43,567 0.0003115650171048601\n",
      "end\n",
      "\n",
      "Control status : Failed\n"
     ]
    }
   ],
   "source": [
    "print(\"Control script according to criterion 5\")\n",
    "print()\n",
    "DATASET = Path('../experiments')\n",
    "\n",
    "error=False\n",
    "for name in inout_per_type:\n",
    "    dist = d(DATASET / f'inout/per_type/{name}.txt')\n",
    "    src, direction, dst = name.split('_')\n",
    "    sy=np.sum(dist.y)\n",
    "    sxy=np.sum(dist.x*dist.y)\n",
    "    if dist.x[0]==0:\n",
    "        s0=dist.y[0]\n",
    "    else:\n",
    "        s0=0\n",
    "    if ((dst==\"all\" and direction==\"out\")) and s0!=0:\n",
    "    #if (dst==\"all\" or (direction==\"in\")) and s0!=0:\n",
    "        rs=rawstats[\"nodes\"][short2longname[src]]\n",
    "        ds=s0/rs\n",
    "        print(f'{src:3} {direction:3} {dst:3} ERROR {int(s0):17,} {ds:<}')\n",
    "        error=True\n",
    "print(\"end\")\n",
    "print()\n",
    "if error:\n",
    "    print(\"Control status : Failed\")\n",
    "else:\n",
    "    print(\"Control status : Successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20dfde5-7e6d-4a40-9c47-4063ff1554a9",
   "metadata": {},
   "source": [
    "- control script according to criterion 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e4fc547c-95b1-427a-b16c-dce95ad23878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control script according to criterion 6\n",
      "\n",
      "rev in  rel OK        11,722,969 / 1,976,476,233     = 0.0059312471378450415 < 0.01 (threshold)\n",
      "end\n",
      "\n",
      "Control status : Successful\n"
     ]
    }
   ],
   "source": [
    "print(\"Control script according to criterion 6\")\n",
    "print()\n",
    "DATASET = Path('../experiments')\n",
    "\n",
    "error=False\n",
    "threshold=0.01 # 5% : threshold value meaning \"small compared to the number of nodes\"\n",
    "for name in ['rev_in_rel']:\n",
    "    dist = d(DATASET / f'inout/per_type/{name}.txt')\n",
    "    src, direction, dst = name.split('_')\n",
    "    sy=np.sum(dist.y)\n",
    "    sxy=np.sum(dist.x*dist.y)\n",
    "    if dist.x[0]==0:\n",
    "        s0=dist.y[0]\n",
    "    else:\n",
    "        s0=0\n",
    "    ds=(sy-s0)/sy\n",
    "    if ds>threshold:\n",
    "        print(f'{src:3} {direction:3} {dst:3} ERROR {int(sy-s0):17,} / {int(sy):<17,} = {ds:<}')\n",
    "        error=True\n",
    "    else:\n",
    "        print(f'{src:3} {direction:3} {dst:3} OK {int(sy-s0):17,} / {int(sy):<17,} = {ds:<} < {threshold} (threshold)')\n",
    "        \n",
    "print(\"end\")\n",
    "print()\n",
    "if error:\n",
    "    print(\"Control status : Failed\")\n",
    "else:\n",
    "    print(\"Control status : Successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7805111e-f2c6-4d50-bff3-7c918b88d651",
   "metadata": {},
   "source": [
    "## Example of Data integrity failures ecountered during this study\n",
    "\n",
    "### Error in the in/out distributions processing (switch fallthrough bug)\n",
    "\n",
    "Experiments based on dataset 2020-05-20 and an incorrect computation of the distributionsincorrect computation of the distributions\n",
    "\n",
    "\n",
    "Control script corresponding to criterion 1 failed\n",
    "\n",
    "Issue has been investigated and fixed (https://forge.softwareheritage.org/rDGRPH6ef89157db57834ad94607f3691e43adaa78a21e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0bc0dcbd-fc4c-49d8-94a5-f3fe09e8a8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control script according to criterion 1\n",
      "\n",
      "cnt in dir ERROR 16,363,987,574 (derived) 8,181,993,787 (raw)\n",
      "dir in all ERROR 15,096,742,782 (derived) 6,914,748,995 (raw)\n",
      "dir in dir ERROR 15,096,742,782 (derived) 6,914,748,995 (raw)\n",
      "dir in rev ERROR 15,096,742,782 (derived) 6,914,748,995 (raw)\n",
      "dir out all ERROR 15,096,742,782 (derived) 6,914,748,995 (raw)\n",
      "dir out cnt ERROR 15,096,742,782 (derived) 6,914,748,995 (raw)\n",
      "dir out dir ERROR 15,096,742,782 (derived) 6,914,748,995 (raw)\n",
      "dir out rev ERROR 15,096,742,782 (derived) 6,914,748,995 (raw)\n",
      "ori out snp ERROR 17,075,708,289 (derived) 108,109,058 (raw)\n",
      "rel in snp ERROR 16,845,902,398 (derived) 14,386,337 (raw)\n",
      "rev in all ERROR 16,831,516,061 (derived) 1,734,773,279 (raw)\n",
      "rev in dir ERROR 16,831,516,061 (derived) 1,734,773,279 (raw)\n",
      "rev in rel ERROR 16,831,516,061 (derived) 1,734,773,279 (raw)\n",
      "rev in rev ERROR 16,831,516,061 (derived) 1,734,773,279 (raw)\n",
      "rev in snp ERROR 16,831,516,061 (derived) 1,734,773,279 (raw)\n",
      "rev out rev ERROR 16,831,516,061 (derived) 1,734,773,279 (raw)\n",
      "snp in ori ERROR 16,967,599,231 (derived) 121,696,833 (raw)\n",
      "snp out all ERROR 16,967,599,231 (derived) 121,696,833 (raw)\n",
      "snp out rel ERROR 16,967,599,231 (derived) 121,696,833 (raw)\n",
      "snp out rev ERROR 16,967,599,231 (derived) 121,696,833 (raw)\n",
      "end\n",
      "\n",
      "Control status : Failed\n"
     ]
    }
   ],
   "source": [
    "# ! raw stats from distribution after the bug fix\n",
    "# and not from the raw stats of the compress graph\n",
    "#\n",
    "rawstats20210403={\"nodes\":\n",
    "          {\n",
    "              \"origin\":108109058,\n",
    "              \"snapshot\":121696833,\n",
    "              \"release\":14386337,\n",
    "              \"commit\":1734773279,\n",
    "              \"directory\":6914748995,\n",
    "              \"content\":8181993787\n",
    "          }\n",
    "         }\n",
    "print(\"Control script according to criterion 1\")\n",
    "print()\n",
    "#DATASET = Path('../experiments/deprecated/20201019/')\n",
    "DATASET = Path('../experiments/deprecated/20210317/')  # latest before bugfix\n",
    "#DATASET = Path('../experiments/deprecated/20210403/') # after bugfix\n",
    "error=False\n",
    "for name in inout_per_type:\n",
    "    dist = d(DATASET / f'inout/per_type/{name}.txt')\n",
    "    src, direction, dst = name.split('_')\n",
    "    sy=np.sum(dist.y)\n",
    "    sxy=np.sum(dist.x*dist.y)\n",
    "    if dist.x[0]==0:\n",
    "        s0=dist.y[0]\n",
    "    else:\n",
    "        s0=0\n",
    "    rs=rawstats20210403[\"nodes\"][short2longname[src]]\n",
    "    if sy==rs:\n",
    "        print(f'{src} {direction} {dst} OK,', end=\" \")\n",
    "    else:\n",
    "        print(f'{src} {direction} {dst} ERROR {int(sy):,} (derived) {int(rs):,} (raw)')\n",
    "        error=True\n",
    "print(\"end\")\n",
    "print()\n",
    "if error:\n",
    "    print(\"Control status : Failed\")\n",
    "else:\n",
    "    print(\"Control status : Successful\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e67cb6-64cd-43e1-88bc-2f3a1a143031",
   "metadata": {},
   "source": [
    "**After bug fix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "524f9103-ca38-409f-b61c-16b813b8aab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control script according to criterion 1\n",
      "\n",
      "cnt in dir OK, dir in all OK, dir in dir OK, dir in rev OK, dir out all OK, dir out cnt OK, dir out dir OK, dir out rev OK, ori out snp OK, rel in snp OK, rev in all OK, rev in dir OK, rev in rel OK, rev in rev OK, rev in snp OK, rev out rev OK, snp in ori OK, snp out all OK, snp out rel OK, snp out rev OK, end\n",
      "\n",
      "Control status : Successful\n"
     ]
    }
   ],
   "source": [
    "print(\"Control script according to criterion 1\")\n",
    "print()\n",
    "DATASET = Path('../experiments/deprecated/20210403/') # after bugfix\n",
    "error=False\n",
    "for name in inout_per_type:\n",
    "    dist = d(DATASET / f'inout/per_type/{name}.txt')\n",
    "    src, direction, dst = name.split('_')\n",
    "    sy=np.sum(dist.y)\n",
    "    sxy=np.sum(dist.x*dist.y)\n",
    "    if dist.x[0]==0:\n",
    "        s0=dist.y[0]\n",
    "    else:\n",
    "        s0=0\n",
    "    rs=rawstats20210403[\"nodes\"][short2longname[src]]\n",
    "    if sy==rs:\n",
    "        print(f'{src} {direction} {dst} OK,', end=\" \")\n",
    "    else:\n",
    "        print(f'{src} {direction} {dst} ERROR {int(sy):,} (derived) {int(rs):,} (raw)')\n",
    "        error=True\n",
    "print(\"end\")\n",
    "print()\n",
    "if error:\n",
    "    print(\"Control status : Failed\")\n",
    "else:\n",
    "    print(\"Control status : Successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b53bec5-eb20-44d7-b7c1-9f7bb48e1ca1",
   "metadata": {},
   "source": [
    "### Data integrity: nodes without ancestors / Compression Pipline\n",
    "\n",
    "Control script corresponding ti criteria 5 on dataset 2020-05-20 \n",
    "(https://annex.softwareheritage.org/public/dataset/graph/2020-05-20/compressed/) \n",
    "lead to the following result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "759ddb72-17bd-4406-a014-fe72d379694a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control script according to criterion 4 : Nodes without ancestors\n",
      "\n",
      "cnt in  dir ERROR       302,918,865 0.033095588214573306\n",
      "dir in  all ERROR         1,968,810 0.0002492925014586481\n",
      "rel in  snp ERROR           428,698 0.02591958892198736\n",
      "rev in  all ERROR        17,852,476 0.009032476941502388\n",
      "snp in  ori ERROR        51,899,904 0.3711569416645763\n",
      "end\n",
      "\n",
      "Control status : Failed\n"
     ]
    }
   ],
   "source": [
    "print(\"Control script according to criterion 4 : Nodes without ancestors\")\n",
    "print()\n",
    "DATASET = Path('../experiments/deprecated/20210403/') # after bugfix\n",
    "error=False\n",
    "for name in inout_per_type:\n",
    "    dist = d(DATASET / f'inout/per_type/{name}.txt')\n",
    "    src, direction, dst = name.split('_')\n",
    "    sy=np.sum(dist.y)\n",
    "    sxy=np.sum(dist.x*dist.y)\n",
    "    if dist.x[0]==0:\n",
    "        s0=dist.y[0]\n",
    "    else:\n",
    "        s0=0\n",
    "    if ((dst==\"all\" and direction!=\"out\") or (direction==\"in\" and src!=\"dir\" and src!=\"rev\")) and s0!=0:\n",
    "    #if (dst==\"all\" or (direction==\"in\")) and s0!=0:\n",
    "        rs=rawstats[\"nodes\"][short2longname[src]]\n",
    "        ds=s0/rs\n",
    "        print(f'{src:3} {direction:3} {dst:3} ERROR {int(s0):17,} {ds:<}')\n",
    "        error=True\n",
    "print(\"end\")\n",
    "print()\n",
    "if error:\n",
    "    print(\"Control status : Failed\")\n",
    "else:\n",
    "    print(\"Control status : Successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e0b5ec-9f42-49b8-8607-dbbfd3ca95d2",
   "metadata": {},
   "source": [
    "**37% of the snaphost nodes were not connected to an upstream origins**\n",
    "\n",
    "It appears that a more recent export (2020-12-15) did not show the same problem.\n",
    "\n",
    "https://annex.softwareheritage.org/public/dataset/graph/2020-12-15/compressed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2d0c4a92-faf3-492d-9071-7b35136aba0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control script according to criterion 4 : Nodes without ancestors\n",
      "\n",
      "dir in  all ERROR         1,343,830 0.00017015696904992107\n",
      "rel in  snp ERROR           427,531 0.025849030719541907\n",
      "rev in  all ERROR        21,591,750 0.010924366121634006\n",
      "snp in  ori ERROR            53,736 0.0003842875974739312\n",
      "end\n",
      "\n",
      "Control status : Failed\n"
     ]
    }
   ],
   "source": [
    "print(\"Control script according to criterion 4 : Nodes without ancestors\")\n",
    "print()\n",
    "DATASET = Path('../experiments/deprecated/20210602/') # after bugfix\n",
    "error=False\n",
    "for name in inout_per_type:\n",
    "    dist = d(DATASET / f'inout/per_type/{name}.txt')\n",
    "    src, direction, dst = name.split('_')\n",
    "    sy=np.sum(dist.y)\n",
    "    sxy=np.sum(dist.x*dist.y)\n",
    "    if dist.x[0]==0:\n",
    "        s0=dist.y[0]\n",
    "    else:\n",
    "        s0=0\n",
    "    if ((dst==\"all\" and direction!=\"out\") or (direction==\"in\" and src!=\"dir\" and src!=\"rev\")) and s0!=0:\n",
    "    #if (dst==\"all\" or (direction==\"in\")) and s0!=0:\n",
    "        rs=rawstats[\"nodes\"][short2longname[src]]\n",
    "        ds=s0/rs\n",
    "        print(f'{src:3} {direction:3} {dst:3} ERROR {int(s0):17,} {ds:<}')\n",
    "        error=True\n",
    "print(\"end\")\n",
    "print()\n",
    "if error:\n",
    "    print(\"Control status : Failed\")\n",
    "else:\n",
    "    print(\"Control status : Successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e782799-614d-4d3f-a5e2-45bafd68c61e",
   "metadata": {},
   "source": [
    "**It appears that now less than 0,04% of the snapshot do not have ancestors. Directory nodes without ancestors decrease from 3.3% to less than 0.02%**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9894c85-e890-49e9-a47a-30354453dc63",
   "metadata": {},
   "source": [
    "### Data integrity: nodes without ancestors / Raw Dataset\n",
    "\n",
    "Due to the update mechanisms of the software heritage project base, having parents without ancestors can have several origins. One of them is the atomicity that is not guaranteed during an update in the bottom-up direction. That is, if there is a problem in the indexing process of new software artifacts, the nodes of the filesystem layer, for example, may have been injected without the nodes of the history or hosting layers having been injected.\n",
    "In most cases, when crawlers return to an origin whose last visit was an error, the injection process based on intrinsic identifiers corrects the problem.\n",
    "\n",
    "Similarly, the process, used up to now, to export the graph and build a compressed version is not atomic. So there may be a time shift of the same type with some objects missing at the frontier of the current injection processes.\n",
    "\n",
    "In both cases, the problems should be only temporary and it is possible to check whether this explains all or some of the nodes without ancestors we have found, by \n",
    "- comparing two exports separated by a time guaranteeing that the crawlers have returned to the failed visits, and checking that most nodes missing an ancestor in the frirst export, have one in the second export.\n",
    "- comparing the 2020-12-15 export with the information contained in the Software Heritage project database. In the case of revisions not linked to an ancestor, it is sufficient to check whether these revisions were seen in visits much older than the export date, or on the contrary close to the limit represented by the export date.\n",
    "\n",
    "We did this on a sample of 1000 revisions without ancestors, identifying for 98.5% of them (see file *rev1000.txt*) the oldest visit in which it was seen (without having to go back in the chain of revisions).\n",
    "\n",
    "A small proportion of these revisions have been seen recently. This invalidates the hypothesis according to which nodes without ancestors are primarily caused by the non-atomicity of the crawling process and the export process.\n",
    "\n",
    "Further investigation is needed. An anomaly report has been filed https://forge.softwareheritage.org/T3660.\n",
    "\n",
    "At this point, we have no evidence that these anomalies have a significant impact on the results presented in this study. Nevertheless, this is one of the limitations of this study, and will need further investigation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ae0508-f86c-436a-94b2-8404a5c8926a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
